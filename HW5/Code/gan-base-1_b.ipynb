{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "racial-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-pontiac",
   "metadata": {},
   "source": [
    "# Define learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absolute-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning parameters\n",
    "batch_size = 512\n",
    "epochs = 100\n",
    "sample_size = 64 # fixed sample size for generator\n",
    "nz = 128 # latent vector size\n",
    "k = 1 # number of steps to apply to the discriminator\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-tenant",
   "metadata": {},
   "source": [
    "# Prepare training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opposite-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to input/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4372cfc5f75c446c8c2fe82adbad9d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/data/MNIST/raw/train-images-idx3-ubyte.gz to input/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to input/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61066cad3cb74899b6e3b8d5a8ae0509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/data/MNIST/raw/train-labels-idx1-ubyte.gz to input/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to input/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7891773d1349f9a505248e4b7192dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/data/MNIST/raw/t10k-images-idx3-ubyte.gz to input/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to input/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12afb8a77808475f9f6c0c23a9feb68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to input/data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)),\n",
    "])\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "# Make input, output folders\n",
    "!mkdir -p input\n",
    "!mkdir -p outputs\n",
    "\n",
    "# Load train data\n",
    "train_data = datasets.MNIST(\n",
    "    root='input/data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-guitar",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(Generator, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-democracy",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silent-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daily-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### GENERATOR #####\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "######################\n",
      "\n",
      "##### DISCRIMINATOR #####\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n",
      "######################\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(nz).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "print('##### GENERATOR #####')\n",
    "print(generator)\n",
    "print('######################')\n",
    "print('\\n##### DISCRIMINATOR #####')\n",
    "print(discriminator)\n",
    "print('######################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-brooks",
   "metadata": {},
   "source": [
    "# Tools for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moved-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers\n",
    "optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optim_d = optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "irish-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.BCELoss() # Binary Cross Entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suited-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g = [] # to store generator loss after each epoch\n",
    "losses_d = [] # to store discriminator loss after each epoch\n",
    "images = [] # to store images generatd by the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sensitive-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "australian-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extraordinary-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the images generated by the generator\n",
    "def save_generator_image(image, path):\n",
    "    save_image(image, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greatest-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the noise vector - fixed to track how GAN is trained.\n",
    "noise = create_noise(sample_size, nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-theme",
   "metadata": {},
   "source": [
    "# Q. Write training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/117 [00:00<00:36,  3.20it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/varun/Documents/HW5 3/Code/gan-base-1_b.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m discriminator_loss_real \u001b[39m=\u001b[39m discriminator_loss(true_predictions, label_real(real_images\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m discriminator_loss_real\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m discriminator_loss_fake \u001b[39m=\u001b[39m discriminator_loss(false_predictions, label_fake(fake_images\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m discriminator_loss_fake\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss_d \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m discriminator_loss_real\u001b[39m.\u001b[39mitem() \u001b[39m+\u001b[39m discriminator_loss_fake\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32m/Users/varun/Documents/HW5 3/Code/gan-base-1_b.ipynb Cell 20\u001b[0m in \u001b[0;36mdiscriminator_loss\u001b[0;34m(output, true_label)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdiscriminator_loss\u001b[39m(output, true_label):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/varun/Documents/HW5%203/Code/gan-base-1_b.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m criterion(output, true_label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:619\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:3095\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3092\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3093\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3095\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7777)\n",
    "\n",
    "def generator_loss(output, true_label):\n",
    "    return criterion(output, true_label)\n",
    "    \n",
    "    \n",
    "    ######################################\n",
    "    \n",
    "def discriminator_loss(output, true_label):\n",
    "    return criterion(output, true_label)\n",
    "    \n",
    "    \n",
    "    ######################################\n",
    "    \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_g = 0.0\n",
    "    loss_d = 0.0\n",
    "    for bi, data in tqdm(enumerate(train_loader), total=int(len(train_data)/train_loader.batch_size)):\n",
    "        ############ YOUR CODE HERE ########## \n",
    "        real_images = data[0]\n",
    "        fake_images = generator(noise)##Generate 512 fake images\n",
    "       \n",
    "        optim_d.zero_grad()\n",
    "        true_predictions = discriminator(real_images)\n",
    "        false_predictions = discriminator(fake_images)\n",
    "        discriminator_loss_real = discriminator_loss(true_predictions, label_real(real_images.size(0)))\n",
    "        discriminator_loss_real.backward()\n",
    "        discriminator_loss_fake = discriminator_loss(false_predictions, label_fake(fake_images.size(0)))\n",
    "        discriminator_loss_fake.backward()\n",
    "        loss_d += discriminator_loss_real.item() + discriminator_loss_fake.item()\n",
    "        optim_d.step()\n",
    "        \n",
    "        \n",
    "        ##GENERATOR:\n",
    "        fake_images = generator(noise)\n",
    "        optim_g.zero_grad()\n",
    "        prediction = discriminator(fake_images)\n",
    "        generator_loss_fake = -generator_loss(prediction, label_fake(fake_images.size(0)))\n",
    "        generator_loss_fake.backward()\n",
    "        optim_g.step()\n",
    "        \n",
    "        \n",
    "        ##Print loss\n",
    "        loss_g += generator_loss_fake.item()\n",
    "        \n",
    "        ######################################\n",
    "    \n",
    "    \n",
    "    # create the final fake image for the epoch\n",
    "    generated_img = generator(noise).cpu().detach()\n",
    "    \n",
    "    # make the images as grid\n",
    "    generated_img = make_grid(generated_img)\n",
    "    \n",
    "    # visualize generated images\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        plt.imshow(generated_img.permute(1, 2, 0))\n",
    "        plt.title(f'epoch {epoch+1}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # save the generated torch tensor models to disk\n",
    "    save_generator_image(generated_img, f\"outputs/gen_img{epoch+1}.png\")\n",
    "    images.append(generated_img)\n",
    "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
    "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
    "    losses_g.append(epoch_loss_g)\n",
    "    losses_d.append(epoch_loss_d)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "chief-jewelry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE TRAINING\n"
     ]
    }
   ],
   "source": [
    "print('DONE TRAINING')\n",
    "torch.save(generator.state_dict(), 'outputs/1b/generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "relative-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generated images as GIF file\n",
    "imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "imageio.mimsave('outputs/1b/generator_images.gif', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "liable-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save the generator and discriminator loss\n",
    "plt.figure()\n",
    "plt.plot(losses_g, label='Generator loss')\n",
    "plt.plot(losses_d, label='Discriminator Loss')\n",
    "plt.legend()\n",
    "plt.savefig('outputs/loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-brother",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d683bd3c49b85e35921f682a7ae57da336b8297a63961b3e9b51a88f00b3577e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
